{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine translation with attension.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOEE6ymwZvgZdVLPcVoiOc6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alihassan7726/Seq2Seq-learning-with-attension/blob/main/Machine_translation_with_attension.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86AYpaWyPa3P"
      },
      "source": [
        "## **Spanish to English translation using Encoder & Decoder model with attension mechanism.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGv42XwlzCai"
      },
      "source": [
        "## Steps inovolved :\n",
        "\n",
        "1. Downlaoding and preparing DataSet .\n",
        "\n",
        "2. Cleaning Text , adding <'START'> and <'END'> tokens . \n",
        "\n",
        "3. Creating word2idx and idx2word dictionaries .\n",
        "\n",
        "4. Padding Sequences . \n",
        "\n",
        "5. Splitting Data .\n",
        "\n",
        "6. Creating tf.keras DataSet . \n",
        "\n",
        "7. Creating Encoder_Class for encoder model and checking input/output shapes . \n",
        "\n",
        "8. Creating Attension_Class for alignment model and checking input/output shapes . \n",
        "\n",
        "9. Creating Decoder_Class for alignment model and checking input/output shapes . \n",
        "10. Defining optimizor , loss function model checkpoint . \n",
        "\n",
        "11. Defining training function and training loop . \n",
        "\n",
        "12. Function for inference and plotting results . \n",
        "\n",
        "13. Predictions .  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lL_FQ82jk5QE",
        "outputId": "2e8f2aab-634a-4975-b7f7-731f04027c31"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EJm3-An_ODr"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyCHvQrKzsEn"
      },
      "source": [
        "## 1. Downloading and preparing DataSet .\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBcxS0V6Ai2d",
        "outputId": "1dc1911e-a5d6-4a62-99af-8330d43af2e2"
      },
      "source": [
        "# Downloading the file\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "print(path_to_zip)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n",
            "/root/.keras/datasets/spa-eng.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAdoSFf1A6Y5"
      },
      "source": [
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LangW9KfBM3W",
        "outputId": "ff399eba-7074-4b0a-afb9-a7d250993fe8"
      },
      "source": [
        "# Opening file\n",
        "with open(path_to_file , 'r' , encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "num_samples = 5\n",
        "# reading 5 lines\n",
        "for line in lines[: min(num_samples , len(lines)-1)]:\n",
        "    input_text , target_text = line.split('\\t')\n",
        "input_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hi.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "X6eQjLhtBezx",
        "outputId": "d6bc1b50-dac0-4a18-a866-0895495647bf"
      },
      "source": [
        "line"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hi.\\tHola.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxGHFVCBzydf"
      },
      "source": [
        "## 2. Cleaning Text , adding <'START'> and <'END'> tokens . \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOwCO4wwBplZ"
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(text):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', text)\n",
        "                 if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(text):\n",
        "  sent = unicode_to_ascii(text.lower().strip())\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  sent = re.sub(r\"([?.!,¿])\", r\" \\1 \", sent)\n",
        "  sent = re.sub(r'[\" \"]+', \" \", sent)\n",
        "\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  sent = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sent)\n",
        "\n",
        "  sent = sent.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  sent = '<start> ' + sent + ' <end>'\n",
        "  return sent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WyHrQXNrCxzU",
        "outputId": "d28f0301-2d6e-499a-af14-135a02a5f7f0"
      },
      "source": [
        "preprocess_sentence(\"I,am interested in games.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<start> i , am interested in games . <end>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ5SWfDJJEBi",
        "outputId": "b9a47916-da29-4198-b1d1-a122c12024d4"
      },
      "source": [
        "pairs = [['<start> go . <end>', '<start> ve . <end>'], ['<start> go . <end>', '<start> vete . <end>'], ['<start> go . <end>', '<start> vaya . <end>'], ['<start> go . <end>', '<start> vayase . <end>'], ['<start> hi . <end>', '<start> hola . <end>']]\n",
        "zip(pairs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<zip at 0x7f97aca71320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_V0awSnJTEj",
        "outputId": "f384b432-1b49-4bae-e0bd-fe65dfa53eea"
      },
      "source": [
        "for i in zip(*pairs):\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('<start> go . <end>', '<start> go . <end>', '<start> go . <end>', '<start> go . <end>', '<start> hi . <end>')\n",
            "('<start> ve . <end>', '<start> vete . <end>', '<start> vaya . <end>', '<start> vayase . <end>', '<start> hola . <end>')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6avlOLWC5bk"
      },
      "source": [
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  word_pairs = [[preprocess_sentence(w) for w in line.split('\\t')]\n",
        "                for line in lines[:num_examples]]\n",
        "  \n",
        "  return zip(*word_pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foF9rBN0JAmr",
        "outputId": "a06cdc05-b06e-44b2-d8e3-3b470aee3763"
      },
      "source": [
        "\n",
        "en, sp = create_dataset(path_to_file, 5)\n",
        "en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<start> go . <end>',\n",
              " '<start> go . <end>',\n",
              " '<start> go . <end>',\n",
              " '<start> go . <end>',\n",
              " '<start> hi . <end>')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "787d_VB5Jg-B",
        "outputId": "dfcbab54-fb65-4417-e9bf-c1cb6cda92b6"
      },
      "source": [
        "# Below we can see very long sentences to be translated so seq2seq with attension is much better then basic one specially in this case.\n",
        "en, sp = create_dataset(path_to_file, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmfFKTCGz1fC"
      },
      "source": [
        "## 3. Creating word2idx and idx2word dictionaries .\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fSZ8Dq-KCVg"
      },
      "source": [
        "# tokenizing and padding\n",
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6nKbWmULXeL"
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoe3gEPtLjPM",
        "outputId": "b76ec9cf-b6a9-4e81-e115-ac60874fbc13"
      },
      "source": [
        "# Limiting the size of data to just 50000 samples to be translated\n",
        "num_examples = 50000\n",
        "input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer = load_dataset(path_to_file,\n",
        "                                                                num_examples)\n",
        "\n",
        "print(input_tensor.shape)\n",
        "print(target_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 16)\n",
            "(50000, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcE9b6Xu0M33"
      },
      "source": [
        "## 5. Splitting Data .\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYrA3A_hMFBG",
        "outputId": "c471ad83-0963-45ee-fd99-bf62d82c4c3f"
      },
      "source": [
        "max_length_targ , max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "print(max_length_targ)\n",
        "print(max_length_inp)\n",
        "\n",
        "# Splitting the data using a 90-10 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.1)\n",
        "\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n",
            "16\n",
            "45000 45000 5000 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdia0yKXMwg7",
        "outputId": "8675a947-aca2-47c4-86c0-8cf9cbb5a2ff"
      },
      "source": [
        "input_tensor_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  7, 40, 72, 33,  6,  3,  2,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTAFxZdVNGK2"
      },
      "source": [
        "# index to word mapping\n",
        "def index_to_word(lang_tokenizer , tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print(f'{t} -----> {lang_tokenizer.index_word[t]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vFOsvSDNrcO",
        "outputId": "698e7d04-c269-47ab-c1d0-21210a6e09cd"
      },
      "source": [
        "index_to_word(inp_lang_tokenizer , input_tensor_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 -----> <start>\n",
            "7 -----> no\n",
            "40 -----> puedo\n",
            "72 -----> ir\n",
            "33 -----> con\n",
            "6 -----> tom\n",
            "3 -----> .\n",
            "2 -----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHfyrhFgNyWq",
        "outputId": "0d9f21d0-2ba3-4134-f0a4-e8be694339d2"
      },
      "source": [
        "\n",
        "index_to_word(targ_lang_tokenizer , target_tensor_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 -----> <start>\n",
            "4 -----> i\n",
            "25 -----> can\n",
            "12 -----> t\n",
            "64 -----> come\n",
            "61 -----> with\n",
            "7 -----> tom\n",
            "3 -----> .\n",
            "2 -----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJO0fWlnOpN3"
      },
      "source": [
        "\n",
        "## 6. Creating a tf.keras.dataset more specifically a generator object to save memory as well as computation power by providing slices/batch of data during execution so that only that small batch is loaded into memory at a particular time  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1w3pzJAOUjp"
      },
      "source": [
        "\n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang_tokenizer.word_index)+1 # Equivalent to num_encoder_tokens\n",
        "vocab_tar_size = len(targ_lang_tokenizer.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iC3pjjFyPwez",
        "outputId": "667aa363-ea55-46e6-ad50-f0a7aead89a0"
      },
      "source": [
        "print(len(dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGocgPYEPzqb",
        "outputId": "8357da2d-30ec-4c91-cdc1-e7751571b07b"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 16]), TensorShape([64, 12]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYcET-Z9P6v-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfa2bf55-ed22-4206-924a-3e14f4011bb9"
      },
      "source": [
        "print(\"Input vocabulary size \" , vocab_inp_size)\n",
        "dataset.take(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input vocabulary size  12999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset shapes: ((64, 16), (64, 12)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "afHV-xnllzoz",
        "outputId": "eda69c25-5261-461f-9a2c-73ab1e89647a"
      },
      "source": [
        "i = 0\n",
        "for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    print(targ.shape)\n",
        "    i+=1\n",
        "print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "(64, 12)\n",
            "703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrWui_sMtasc",
        "outputId": "c0186a22-3e30-4227-cd29-24f252f48acf"
      },
      "source": [
        "print(input_tensor_train.shape[1]) # Equivalent to max_source_lenght\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vah1sgFjrvSI"
      },
      "source": [
        "### return_sequences=True , return_state=False :                          \n",
        "return stacked hidden states (num_timesteps * num_cells): one hidden state output for each input time step\n",
        "\n",
        "\n",
        "### return_sequences=True , return_state=True :\n",
        "return 3 arrays: stacked hidden states, last state_h, last state_c\n",
        "\n",
        "\n",
        "### return_sequences=False, return_state=True :\n",
        "return 3 arrays: state_h, state_h, state_c\n",
        "\n",
        "\n",
        "### return_sequences=False, return_state=False :\n",
        "returns the last hidden state state_h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olHmAQpF0-zQ"
      },
      "source": [
        "## 7. Creating Encoder_Class for encoder model and checking input/output shapes . \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_sOY3h_q_eN"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCDGjWIDs3cK",
        "outputId": "e56eea1e-fde2-4f58-9a10-5f9c67f608c0"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print('Encoder output shape: (batch size, sequence length, units)', sample_output.shape)\n",
        "print('Encoder Hidden state shape: (batch size, units)', sample_hidden.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDCidP3Tuae7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4336c239-c073-45c2-f76d-70b28aa09d1b"
      },
      "source": [
        "arr = np.zeros(shape = (1,5))\n",
        "arr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTT9NyzJzMpA",
        "outputId": "12020e12-3aac-416d-9ca8-190e727308dd"
      },
      "source": [
        "\n",
        "tf.expand_dims(arr, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1, 5), dtype=float64, numpy=array([[[0., 0., 0., 0., 0.]]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZclBHKqc1HIl"
      },
      "source": [
        "## 8. Creating Attension_Class for alignment model and checking input/output shapes . \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcpb0LEWzvcp"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhluScsP10rs",
        "outputId": "dd2c084d-167d-4a75-83a3-363d29440a9a"
      },
      "source": [
        "\n",
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units)\", attention_result.shape)\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1)\", attention_weights.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5egcuAHh1MoC"
      },
      "source": [
        "## 9. Creating Decoder_Class for alignment model and checking input/output shapes . \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz2S6GIo2EPj"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqumSnqfoomb",
        "outputId": "ecbc3360-4ce8-4106-ac1a-0b4b5c79154f"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print('Decoder output shape: (batch_size, vocab size)', sample_decoder_output.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 6817)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3W_HWYYji8H"
      },
      "source": [
        "## 10. Defining optimizor , loss function , model checkpoint . "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqIEJgGOpnMG"
      },
      "source": [
        "# Initialize optimizer and loss functions\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "# Loss function\n",
        "def loss_function(real, pred):\n",
        "\n",
        "  # Take care of the padding. Not all sequences are of equal length.\n",
        "  # If there's a '0' in the sequence, the loss is being nullified\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zqq4G0HnkV0V"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xkLRUcTHk8zv",
        "outputId": "aca242e8-80b2-4e65-c839-ec375ccb047a"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWY84ei4lFoV",
        "outputId": "a4283157-a434-480c-d6a6-3e5e83f1f8cd"
      },
      "source": [
        "tf.random.uniform((2*5, 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
              "array([[0.505347  ],\n",
              "       [0.15939331],\n",
              "       [0.07847762],\n",
              "       [0.8046496 ],\n",
              "       [0.71810555],\n",
              "       [0.50567234],\n",
              "       [0.2876259 ],\n",
              "       [0.72645986],\n",
              "       [0.81402516],\n",
              "       [0.08972228]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9LG5NmLnZDZ",
        "outputId": "10b49482-7179-4279-8371-2990f754ed9e"
      },
      "source": [
        "tf.expand_dims([2]*5,1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 1), dtype=int32, numpy=\n",
              "array([[2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzev5O4a1pQT"
      },
      "source": [
        "## 11. Defining training function and training loop . "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GtEOHE2oTJI"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5hRf1hjoZuN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ad5911-64d8-4ffa-c63b-9ce33ca13bc6"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print(f'Epoch {epoch+1} Batch {batch} Loss {batch_loss.numpy():.4f}')\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "  print(f'Epoch {epoch+1} Loss {total_loss/steps_per_epoch:.4f}')\n",
        "  print(f'Time taken for 1 epoch {time.time()-start:.2f} sec\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.7238\n",
            "Epoch 1 Batch 100 Loss 2.2359\n",
            "Epoch 1 Batch 200 Loss 1.9210\n",
            "Epoch 1 Batch 300 Loss 1.9224\n",
            "Epoch 1 Batch 400 Loss 1.6647\n",
            "Epoch 1 Batch 500 Loss 1.6364\n",
            "Epoch 1 Batch 600 Loss 1.4834\n",
            "Epoch 1 Batch 700 Loss 1.3497\n",
            "Epoch 1 Loss 1.8805\n",
            "Time taken for 1 epoch 93.95 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.2303\n",
            "Epoch 2 Batch 100 Loss 1.1513\n",
            "Epoch 2 Batch 200 Loss 1.0473\n",
            "Epoch 2 Batch 300 Loss 1.1273\n",
            "Epoch 2 Batch 400 Loss 0.9585\n",
            "Epoch 2 Batch 500 Loss 0.9079\n",
            "Epoch 2 Batch 600 Loss 0.8674\n",
            "Epoch 2 Batch 700 Loss 0.7378\n",
            "Epoch 2 Loss 1.0362\n",
            "Time taken for 1 epoch 81.19 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.6980\n",
            "Epoch 3 Batch 100 Loss 0.6528\n",
            "Epoch 3 Batch 200 Loss 0.5398\n",
            "Epoch 3 Batch 300 Loss 0.4933\n",
            "Epoch 3 Batch 400 Loss 0.5095\n",
            "Epoch 3 Batch 500 Loss 0.6867\n",
            "Epoch 3 Batch 600 Loss 0.5420\n",
            "Epoch 3 Batch 700 Loss 0.5346\n",
            "Epoch 3 Loss 0.6176\n",
            "Time taken for 1 epoch 80.26 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.4154\n",
            "Epoch 4 Batch 100 Loss 0.4405\n",
            "Epoch 4 Batch 200 Loss 0.4677\n",
            "Epoch 4 Batch 300 Loss 0.3657\n",
            "Epoch 4 Batch 400 Loss 0.3900\n",
            "Epoch 4 Batch 500 Loss 0.4122\n",
            "Epoch 4 Batch 600 Loss 0.3877\n",
            "Epoch 4 Batch 700 Loss 0.4335\n",
            "Epoch 4 Loss 0.4006\n",
            "Time taken for 1 epoch 78.39 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.2839\n",
            "Epoch 5 Batch 100 Loss 0.2819\n",
            "Epoch 5 Batch 200 Loss 0.2879\n",
            "Epoch 5 Batch 300 Loss 0.2595\n",
            "Epoch 5 Batch 400 Loss 0.2509\n",
            "Epoch 5 Batch 500 Loss 0.2209\n",
            "Epoch 5 Batch 600 Loss 0.2440\n",
            "Epoch 5 Batch 700 Loss 0.3007\n",
            "Epoch 5 Loss 0.2742\n",
            "Time taken for 1 epoch 77.75 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.1755\n",
            "Epoch 6 Batch 100 Loss 0.1428\n",
            "Epoch 6 Batch 200 Loss 0.2169\n",
            "Epoch 6 Batch 300 Loss 0.2505\n",
            "Epoch 6 Batch 400 Loss 0.2105\n",
            "Epoch 6 Batch 500 Loss 0.2400\n",
            "Epoch 6 Batch 600 Loss 0.1869\n",
            "Epoch 6 Batch 700 Loss 0.2249\n",
            "Epoch 6 Loss 0.1982\n",
            "Time taken for 1 epoch 77.02 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.1140\n",
            "Epoch 7 Batch 100 Loss 0.1503\n",
            "Epoch 7 Batch 200 Loss 0.1315\n",
            "Epoch 7 Batch 300 Loss 0.1390\n",
            "Epoch 7 Batch 400 Loss 0.1470\n",
            "Epoch 7 Batch 500 Loss 0.1750\n",
            "Epoch 7 Batch 600 Loss 0.1563\n",
            "Epoch 7 Batch 700 Loss 0.1932\n",
            "Epoch 7 Loss 0.1496\n",
            "Time taken for 1 epoch 77.00 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1341\n",
            "Epoch 8 Batch 100 Loss 0.0974\n",
            "Epoch 8 Batch 200 Loss 0.1213\n",
            "Epoch 8 Batch 300 Loss 0.1625\n",
            "Epoch 8 Batch 400 Loss 0.1446\n",
            "Epoch 8 Batch 500 Loss 0.1276\n",
            "Epoch 8 Batch 600 Loss 0.1217\n",
            "Epoch 8 Batch 700 Loss 0.1704\n",
            "Epoch 8 Loss 0.1198\n",
            "Time taken for 1 epoch 77.39 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.1039\n",
            "Epoch 9 Batch 100 Loss 0.1092\n",
            "Epoch 9 Batch 200 Loss 0.1026\n",
            "Epoch 9 Batch 300 Loss 0.1178\n",
            "Epoch 9 Batch 400 Loss 0.0859\n",
            "Epoch 9 Batch 500 Loss 0.1388\n",
            "Epoch 9 Batch 600 Loss 0.1195\n",
            "Epoch 9 Batch 700 Loss 0.1014\n",
            "Epoch 9 Loss 0.0993\n",
            "Time taken for 1 epoch 76.67 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0835\n",
            "Epoch 10 Batch 100 Loss 0.0741\n",
            "Epoch 10 Batch 200 Loss 0.0885\n",
            "Epoch 10 Batch 300 Loss 0.0887\n",
            "Epoch 10 Batch 400 Loss 0.1011\n",
            "Epoch 10 Batch 500 Loss 0.0896\n",
            "Epoch 10 Batch 600 Loss 0.0721\n",
            "Epoch 10 Batch 700 Loss 0.0748\n",
            "Epoch 10 Loss 0.0890\n",
            "Time taken for 1 epoch 78.14 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MRdfaJE2WVj"
      },
      "source": [
        "## 12. Function for inference and plotting results . \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZX9A9QEHnYv"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Dx34htyKH4a"
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d76fro4iKIt_"
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input:', sentence)\n",
        "  print('Predicted translation:', result)\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')),\n",
        "                                  :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ccoe8jPvKQM5",
        "outputId": "7f754856-15fa-45a1-9b31-846bae43978b"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f97aa881750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9mZS7e32ZZi"
      },
      "source": [
        "## 13. Predictions . "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "B0uKHRUWKTXg",
        "outputId": "b3ab2382-5fd4-4505-de38-6d7b405b044d"
      },
      "source": [
        "translate(u'hace mucho frio aqui.')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> hace mucho frio aqui . <end>\n",
            "Predicted translation: it s very cold here . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "ESVAppPNKZnh",
        "outputId": "7d038f16-d6d2-45bd-86b8-dc828f757ddb"
      },
      "source": [
        "translate(u'esta es mi vida.')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> esta es mi vida . <end>\n",
            "Predicted translation: this is my life . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAJwCAYAAAAjo60MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7TlB13f/c83TEgKISD3YElAEVGujSMXsRjFJYrK80ipN8AAlnRZL+lD1ac8XVRKQQWjFgtSAsq9Aqa1iIg2ChTKRQwUuSogdyHc5JIbSUi+zx97jxwOM2HOyWR+333yeq111uzz2/uc+Z7fmpn9nt+1ujsAACzvmKUHAABgRZgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAaqqm+oqldU1Z2XngUAOHqE2UynJzktySMWngMAOIrKTcxnqapK8oEk5yb5wSS36u4rFh0KADgqbDGb57QkN0jyc0m+mOT+i04DABw1wmye05Oc090XJ3nh+nMA4FrArsxBqur6ST6W5Pu7+zVVdbckr09yUnd/dtnpAIBrmi1ms/yzJJ/q7tckSXe/Jcl7kvzoolMBwAapqutX1U9U1Q2XnmWnhNksD03y/G3Lnp/kYUd/FADYWD+c5FlZva9uFLsyh6iqWyd5f5Jv6u73bFn+j7M6S/Obu/vdC40HABujql6Z5BZJLu7u/UvPsxPCDADYM6rqNkneneTuSd6Q5NTufueSM+2EXZmDVNXJ6+uYHfS5oz0PAGyghyZ5zfo47T/Ohl3dQJjN8v4kN9u+sKpusn4OALhqP5HkeevHL0jy4ENt9JhImM1SSQ62b/mEJF84yrMAwEapqm9LclKSc9aLXprkekm+e7Ghdmjf0gOQVNVvrR92kl+pqou3PH2drPaTv+WoDwYAm+X0JC/p7guTpLsvq6oXZ3V1g3OXHOxwCbMZ7rz+tZJ8U5LLtjx3WZI3JznraA8FAJuiqo7L6jIZP7btqecn+dOqOuFAsE3mrMwh1vu/X5zkEd19wdLzAMAmqaqbZnV/6ed395XbnntIkj/r7vMXGW4HhNkQVXWdrI4ju+smndYLABw5Dv4foruvSPLBJNddehYAYBm2mA1SVadntW/8Id39qaXnAYDpqur9OfgVDb5Cd3/dNTzO1ebg/1l+Psltk/xdVX0kyUVbn+zuuywyFQDM9ZQtj09I8qgkb0zy+vWye2V1dYNfP8pz7Yowm+Wcr/4SAOCA7v6H4KqqZyd5Ynf/8tbXVNWjk9zxKI+2K3ZlAgB7QlV9Pqt7Y7532/LbJXlzd5+4zGSHz8H/AMBecVGS0w6y/LQkFx9k+Th2ZQ5SVddN8u+yOgHg5CTHbn2+u6+zxFwAsCF+M8lTq2p/kjesl90zqzsCPHapoXZCmM3yH5P8SJJfyeoP1y8kuU2SH03ymOXGAoD5uvtJVfWBJGdmdReAJHlXktO7+8WLDbYDjjEbZH3K7091959U1QVJ7tbdf1tVP5Xkvt39oIVHHKmqHp4vbWX8suvAbcKp0bDXVdXXJPm+HPzv6OMWGQqGssVsllskOXDV/wuT3Gj9+E+SPHGRiYarql9I8ugkT09ynyS/neR268fuLwoLq6p7JnlZkkuT3CzJ3yU5af35B5IIM64RVXWjbDuWvrv/fqFxDpuD/2f5UJJbrR+/N8n91o/vleSSRSaa75FJzujuRye5PMlTuvsBWV2v5pRFJwOS5NeSvCDJ12Z127nvymrL2XnxH06OsKo6papeXlWXJPl0kk+uPz61/nU8W8xm+YMk983qgMUnJ/m9qnpkVv+g/dqSgw32j7O6kGCyitcDp0L/3nr5I5cYCvgHd0nyk93dVXVFkuO6+31V9f8m+a9ZRRscKc/Kam/TTyb5aA7zjgCTCLNB1lt9Djw+p6o+nOTeSd7d3X+03GSjnZ/kplltbfxgVlsX35LV7syN+wsJe9BlWx5/PKst2e/K6nCNWx30K2D37p7knt399qUH2S1hNkhV3SfJ67r7i0nS3X+R5C+qal9V3ae7X73shCO9IskDkrw5ye8k+c2q+uEkpybZiDNwYI97c5JvTfLuJK9K8viqukWShyR564JzsTe9P8lxSw9xdTgrc5D1Zv6TuvsT25bfJMknXMfsK1XVMUmOORCzVfUjWW9lTPL07r58yfng2m59PakbdPcrq+pmSZ6bL/0dfXh3v23RAdlTquq7kvzbJP9q+9X/N4UwG6Sqrkxyi+7+5Lblt09y3ibcSuJoq6qTk3y4t/1BrqpKcuvu/tAykwFwtK0vNXVckutkdebvF7c+vwnvo3ZlDlBVf7h+2EmeX1WXbnn6OknulOR1R32wzfD+rE69/8S25TdeP2crI8C1x88sPcDVJcxm+PT610rymXz5pTEuS/K/kzzjaA+1ISoHP8j/hKxOzQeOsvXFsg9rd4yLQHMkdfdzlp7h6hJmA3T3w5NkfRuJs7r7omUnmq+qfmv9sJP8SlVtvTntdbI6M+ctR30wIEmesuXxCUkeldXla16/XnavrP6O/vpRnotrgfXJJQ9N8vVJHtPdn6qqeyf5aHe/f9npvjrHmA2yPpA93X3l+vNbJvmBJO/sbrsyt6iqV64ffkdW/9hvPSX/sqyuKH5Wd7/nKI8GbFFVz87qkj+/vG35o5Pcsbsfsshg7ElV9S1J/jyrQ1numOQO6+vmPTbJ7bv7x5ec73AIs0Gq6uVJ/qS7n1xVJyT56yTXz+p/nD/Z3c9ddMCBqupZSc7s7s8vPQvwlarq80lO3X6GXFXdLsmbN+FgbDbH+j/tr+7uX1qfCHDXdZjdK8kLu3v8HWHsypxlf5JfXD9+YJLPJ7ltkgcn+fmsTjNniwO7gQ+oqn+U1an47+nuDy4z1eax3g6tqh6Y5KXdffn68SF1938/SmNtkouSnJbVbea2Oi3JxdtfDFfTt2R11f/tPpbV/ajHE2aznJDks+vH35PkD9ZvBq9I8tTlxpprvZvkjd3921V13ayOY7ljksuq6oe6++WLDjiU9bYj5yS5ZVZn/p5zFa/rOAv4YH4zyVPX1zN7w3rZPZOcnuSxSw3FnnVJkq85yPI75CvP3h/JTcxn+VCSe1fV9bO6gfm56+U3jv9ZHsr98qV/7B+Q5AZZvYk+Nv7RvyrW22Hq7mMOXPR5/fhQH6LsILr7SVkdiH3nJL+x/rhzktO7203MOdJekuSXqurA1f+7qm6T5IlJ/ttSQ+2EY8wGqap/mdXZTBdmdd/HU7v7yqr6uST/d3d/16IDDlRVX0hyu+7+SFU9M8nnuvvfrP8ivq27b7DogENZb7u3PuPr3kluni//z21399OWmQpIkqo6MckfJ7lLVsdon5/VLszXJfm+TbjqgV2Zg3T306vqvCQnJzn3wNmZSf42yWOWm2y085Pcqao+ltVWoDPWy09I4nZMh2a97UJVPSTJM/Olaw5u/Z9tJxFmsKD1iWDfvr4106lZ/efpzd39Z8tOdviE2RBVdcMkd+nu1yR507anP5vknUd/qo3wu0lelOSjSa7I6jTpJLlHVme1cnDW2+48IcmTkjzuwP1Z+UrrMzG/bn39qAtyFRebdVYmR8rW99HufkWSV2x57t5ZXXrqM4sNeJiE2RxXJnl5Vd2vu197YGFV3TWrP1xfu9hkg3X346rq7UlOSfLi7j5wPbMvZnVMAQdhve3aiUmeLcq+qp9NcsH68cbfIoeNsSfeRx38P0R3X5DVQYs/se2phyb50+7+1NGfamNckuS7k5xbVbdeL7tuVsfqcWjW2869IMn3Lz3EdN39nO4+cM/fH8rqz9TvrZd/2ceCY7LH7JX3UWE2y3OT/PP15QsO3Angx5M8e8mhJquqByd5cZJ3Z3XNt2PXTx2TL10Tjm2st117VJLvq6r/UVX/sar+/daPpYcb6uIkz0ny8ap6ZlV9x9IDsadt/PuoMJvl3Ky2YvzA+vP7ZrUF46WLTTTfLyZ5ZHf/P1nthjvgDUnutsxIG8F6251/meR7k3xbVluC/vmWjwctONdY61vg3CKr3Zu3ymoL7Qer6ler6k7LTscetPHvo8JskPVZmM/PlzbDPjTJi7rbWXKH9g350o2Rt7owq+OBODjrbXcek+TfdPfNu/tO3X3nLR93WXq4qbr7ou5+fnffP6vjfH4tqzfOtyw7GXvNXngfdfD/PM9N8qaqOjmr/5Hfd+F5pvtokttndd23re6T1WVGODjrbXeuk+QPlx5iU1XV8Um+K6tLtNw+yYeXnYg9aqPfR20xG6a735Hk7VkdZPyR7n7jwiNNd3aS31qfCp0kt66q07O6pIFrSh2a9bY7z8rq3rUcplr5nqp6TpKPZ/Xn66NJ7tvdt112OvaiTX8ftcVspucm+U9J/t3Sg0zX3U9aX7vm3CTHJ3llkkuTnNXd7i96CNbbrl0vyb+oqvsleWu2XYy3u39ukalm+1hWu8dfnuRhSV625fIs7EJVvSvJN3S39/BD29j3UbdkGqiqbpzVgbJP7+7zl55nE1TV9ZJ8c1Zbgd/Z3S75cBist52pqldexdPttmlfqaoemeT3u/uzS8+yV1TVzyS5SXf/h6VnmWqT30eFGQDAEI4xAwAYQpgBAAwhzAarqjOWnmETWW87Z53tjvW2O9bbzllnu7OJ602YzbZxf6CGsN52zjrbHettd6y3nbPOdmfj1pswAwAY4lp/VuZ167g+PtdfeoyDujyX5tgct/QYG8d62znrbHest92x3nZu9DqrpQc4tMv70hxbM9fbBf2ZT3X3zbYvv9ZfnO74XD/3qI26WwMAjFH7rvUpsSvnXv7C7bfES2JXJgDAGMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCFGhllVnVZVXVU3vTqvAQDYJCPCrKpeVVVP2eGXvS7JSUk+fQ2MBABw1O1beoDd6u7Lkpy/9BwAAEfK4lvMqurZSb4jyU+vd012ktusn75rVf1FVV1cVedV1albvu7LdmVW1Q2r6nlV9Ymq+kJVva+q/vXR/nkAAHZr8TBLcmaS1yd5Vla7Jk9K8uH1c7+S5N8mOTWrXZYvqKo6xPd5fJI7J/mBJN+Y5BFJ/u6aGxsA4MhafFdmd3+uqi5LcnF3n58kVXWH9dOP6e5Xrpc9Lsn/TvK1ST5ykG91SpI3d/cb159/8FC/Z1WdkeSMJDk+1zsiPwcAwNU1YYvZVXnrlscfXf9680O89mlJfqSq/qqqzqqq7zjUN+3us7t7f3fvPzbHHalZAQCululhdvmWx73+9aAzd/fLs9pqdlaSmyZ5WVU965odDwDgyJkSZpcluc7V/Sbd/anufl53PyzJTyY5vapsEgMANsLix5itfSDJ3avqNkkuzC6CcX0M2puTvCOrn+uBSd7X3ZcesSkBAK5BU7aYnZXVVrN3JvlkkpN38T0uTfKEJH+V5LVJbpDkB4/UgAAA17Tq7q/+qj3sxLpx36Puu/QYALCRat+UnW+b5dzLX/im7t6/ffmULWYAANd6wgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEPsW3qApdUxx+SY611/6TE2zid/9C5Lj7BxPn3PLy49wkb65sefv/QIG6kvvGjpETZOX/KFpUfYSFdecsnSI+wptpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAyx0WFWVc+uqj9aeg4AgCNh39IDXE1nJqmlhwAAOBI2Osy6+3NLzwAAcKTsmV2ZVXWfqnpDVV1YVZ+rqjdW1Z2WnhEA4HBt9BazA6pqX5KXJPmdJA9OcmySU5NcseRcAAA7sSfCLMmJSW6U5KXd/bfrZX99qBdX1RlJzkiS4+v61/x0AACHYaN3ZR7Q3X+f5NlJ/rSqXlZVj6qqk6/i9Wd39/7u3n/dOv6ozQkAcFX2RJglSXc/PMk9krw6yQOS/E1V3W/ZqQAADt+eCbMk6e6/6u4ndvdpSV6V5PRlJwIAOHx7Isyq6rZV9atV9W1VdUpVfWeSuyR559KzAQAcrr1y8P/FSW6f5PeT3DTJx5O8IMkTlxwKAGAnNjrMuvthWz594FJzAAAcCXtiVyYAwF4gzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMMS+pQdYWl95Za685AtLj7Fxbvqcv1x6hI1ziz87aekRNtInf/v4pUfYSNf93VstPcLGueFrP7D0CBvpyksuWXqEPcUWMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhiXJhV1auq6mlV9etV9fdV9cmqOrOqjquqp1bVZ6vqQ1X10PXrX1FVT9n2PU6sqour6oHL/BQAADs3LszWHpzkgiT3SPKrSf5Tkv+R5N1J9id5TpJnVtVJSZ6R5Mer6rgtX/9jSS5M8tKjOTQAwNUxNcze0d2P7e73JPmNJJ9Kcnl3P7m735vkcUkqyb2T/PckVyb5oS1f/4gkz+3uyw/2zavqjKo6r6rOuzyXXqM/CADA4ZoaZm898KC7O8knkrxty7LLk3wmyc27+9Ikz8sqxlJVd0xy9yS/c6hv3t1nd/f+7t5/bI471MsAAI6qfUsPcAjbt3T1IZYdCMtnJnlrVZ2cVaC9vrvfdc2OCABwZE3dYrYj3f2OJH+R5JFJHpLkd5edCABg56ZuMduNZyT5L1ltWXvRwrMAAOzYnthitvaiJJcleXF3X7D0MAAAOzVui1l3n3aQZXc6yLJbblt0oyT/KFdx0D8AwGTjwmynqurYJDdJ8stJ/k93v3bhkQAAdmUv7Mq8d5KPJfm2rA7+BwDYSBu/xay7X5XVxWYBADbaXthiBgCwJwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgiH1LDzDClVcsPcHG6SuXnmDzfPFDH1l6hI10s589ZekRNtI7/z//ru3Up+/09UuPsJFOecKnlx5hMx3ifdQWMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQI8Osqp5dVX+0/fH682Oq6ulV9emq6qo6bbFBAQCOoH1LD3AYzkxSWz6/f5KHJzktyfuS/P0CMwEAHHHjw6y7P7dt0e2SfKy7X7fEPAAA15SRuzK32r5bM8lvJjl5vRvzA+vlVVW/WFV/W1WXVNXbquohy00NALBz47eYbXNmkg8meUSSb01yxXr545M8KMlPJ/mbJPdK8oyq+kx3v2yJQQEAdmqjwqy7P1dVFyS5orvPT5Kqun6SRyX5nu5+zfql76+qu2cVal8RZlV1RpIzkuT4XO+ozA4A8NVsVJgdwjcnOT7Jn1RVb1l+bJIPHOwLuvvsJGcnyYl14z7YawAAjra9EGYHjpP7wSQf2vbc5Ud5FgCAXdsLYfbOJJcmOaW7X7H0MAAAu7XxYdbdF1TVWUnOqqpK8uokJyS5Z5Ir17stAQDG2/gwW3tMko8n+fkkT0vy+SRvSfKkJYcCANiJkWHW3Q872OP152clOWvbsk7yn9cfAAAbafwFZgEAri2EGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhti39ABwrdG99AQb6Yvv+8DSI2ykO5z5yaVH2Dgvf89rlx5hI33/M++/9Aib6SMHX2yLGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhti39ABLqKozkpyRJMfnegtPAwCwcq3cYtbdZ3f3/u7ef2yOW3ocAIAk19IwAwCYSJgBAAyxZ8Osqn6mqv566TkAAA7Xng2zJDdN8o1LDwEAcLj2bJh192O7u5aeAwDgcO3ZMAMA2DTCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQ+xbegAAjrwrL7po6RE2zvf+Xw9deoSN9NTXPW3pETbS7U8++HJbzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDbEyYVdXPV9UHlp4DAOCasjFhBgCw1x2RMKuqE6vqRkfie+3g97xZVR1/NH9PAIBr0q7DrKquU1X3q6r/muT8JHddL79hVZ1dVZ+oqguq6n9V1f4tX/ewqrqwqu5bVW+vqouq6pVVddtt3/8Xq+r89Wufm+SEbSPcP8n569/r3rv9OQAApthxmFXVHavqSUk+nORFSS5K8r1JXl1VleRlSb42yQ8k+SdJXp3kFVV10pZvc1ySRyd5RJJ7JblRkv+y5ff44SSPT/JLSU5N8jdJHrVtlBck+fEkN0hyblW9t6r+/fbAAwDYFIcVZlV1k6r6uap6U5L/k+QOSc5McsvufmR3v7q7O8l3Jrlbkgd19xu7+73d/Zgk70vy0C3fcl+Sn16/5q1Jzkpy2jrskuRfJ3lOdz+9u9/d3U9I8satM3X3F7v7j7v7x5LcMskvr3//91TVq6rqEVW1fSvbgZ/njKo6r6rOuzyXHs4qAAC4xh3uFrOfTfLkJF9IcvvufkB3/353f2Hb674lyfWSfHK9C/LCqrowyZ2SfP2W113a3X+z5fOPJrlukq9Zf/5NSV6/7Xtv//wfdPfnu/t3u/s7k3xrklsk+Z0kDzrE68/u7v3dvf/YHHcVPzYAwNGz7zBfd3aSy5P8RJK3V9UfJHlekj/v7iu2vO6YJB9P8k8P8j0+v+XxF7c911u+fseq6risdp0+JKtjz96R1Va3l+zm+wEALOGwQqi7P9rdT+jub0zy3UkuTPLCJB+pql+vqrutX/rmrLZWXbnejbn14xM7mOtdSe65bdmXfV4r315VT8/q5IP/nOS9Sb6lu0/t7id392d28HsCACxqx1uouvsN3f1TSU7Kahfn7ZP8ZVX90yR/luS1SV5SVd9XVbetqntV1X9YP3+4npzk9Kp6ZFV9Q1U9Osk9tr3mIUn+Z5ITk/xYklt39y9099t3+jMBAExwuLsyv0J3X5rknCTnVNXNk1zR3V1V98/qjMpnJLl5Vrs2X5vkuTv43i+qqq9L8oSsjln7wyS/keRhW17251mdfPD5r/wOAACbp1YnU157nVg37nvUfZceA4CF1bfeeekRNtJTz3na0iNspNuffP6bunv/9uVuyQQAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEPuWHgAAJrck32QAAAJKSURBVOi/fNvSI2ykf3XKty89woY656BLbTEDABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQ+5YeYAlVdUaSM5Lk+Fxv4WkAAFaulVvMuvvs7t7f3fuPzXFLjwMAkORaGmYAABMJMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwRHX30jMsqqo+meSDS89xCDdN8qmlh9hA1tvOWWe7Y73tjvW2c9bZ7kxeb6d09822L7zWh9lkVXVed+9feo5NY73tnHW2O9bb7lhvO2ed7c4mrje7MgEAhhBmAABDCLPZzl56gA1lve2cdbY71tvuWG87Z53tzsatN8eYAQAMYYsZAMAQwgwAYAhhBgAwhDADABhCmAEADPH/AwDkvDWlUKtVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "bO0qBCVwKb4W",
        "outputId": "94a423ac-f265-49b5-8ee4-a95f647c0aff"
      },
      "source": [
        "translate(u'¿todavia estan en casa?')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> ¿ todavia estan en casa ? <end>\n",
            "Predicted translation: are you still at home ? <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsqIsQfkKd-6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}